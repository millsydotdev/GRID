/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { SendLLMMessageParams, OnText, OnFinalMessage, OnError } from '../../common/sendLLMMessageTypes.js';
import { IMetricsService } from '../../common/metricsService.js';
import { displayInfoOfProviderName, FeatureName } from '../../common/gridSettingsTypes.js';
import { sendLLMMessageToProviderImplementation } from './sendLLMMessage.impl.js';

export const sendLLMMessage = async (
	{
		messagesType,
		messages: messages_,
		onText: onText_,
		onFinalMessage: onFinalMessage_,
		onError: onError_,
		abortRef: abortRef_,
		logging: { loggingName, loggingExtras },
		settingsOfProvider,
		modelSelection,
		modelSelectionOptions,
		overridesOfModel,
		chatMode,
		separateSystemMessage,
		mcpTools,
	}: SendLLMMessageParams,

	metricsService: IMetricsService
) => {
	const { providerName, modelName } = modelSelection;

	// only captures number of messages and message "shape", no actual code, instructions, prompts, etc
	const captureLLMEvent = (eventId: string, extras?: object) => {
		metricsService.capture(eventId, {
			providerName,
			modelName,
			customEndpointURL: providerName !== 'auto' ? settingsOfProvider[providerName]?.endpoint : undefined,
			numModelsAtEndpoint: providerName !== 'auto' ? settingsOfProvider[providerName]?.models?.length : undefined,
			...(messagesType === 'chatMessages'
				? {
						numMessages: messages_?.length,
					}
				: messagesType === 'FIMMessage'
					? {
							prefixLength: messages_.prefix.length,
							suffixLength: messages_.suffix.length,
						}
					: {}),
			...loggingExtras,
			...extras,
		});
	};
	const submit_time = new Date();

	let _fullTextSoFar = '';
	let _aborter: (() => void) | null = null;
	const _setAborter = (fn: () => void) => {
		_aborter = fn;
	};
	let _didAbort = false;

	const onText: OnText = (params) => {
		const { fullText } = params;
		if (_didAbort) {return;}
		onText_(params);
		_fullTextSoFar = fullText;
	};

	const onFinalMessage: OnFinalMessage = (params) => {
		const { fullText, fullReasoning, toolCall } = params;
		if (_didAbort) {return;}
		captureLLMEvent(`${loggingName} - Received Full Message`, {
			messageLength: fullText.length,
			reasoningLength: fullReasoning?.length,
			duration: new Date().getMilliseconds() - submit_time.getMilliseconds(),
			toolCallName: toolCall?.name,
		});
		onFinalMessage_(params);
	};

	const onError: OnError = ({ message: errorMessage, fullError }) => {
		if (_didAbort) {return;}
		console.error('sendLLMMessage onError:', errorMessage);

		// handle failed to fetch errors, which give 0 information by design
		if (errorMessage === 'TypeError: fetch failed') {
			// Skip "auto" - it's not a real provider
			if (providerName !== 'auto') {
				errorMessage = `Failed to fetch from ${displayInfoOfProviderName(providerName).title}. This likely means you specified the wrong endpoint in GRID Settings, or your local model provider like Ollama is powered off.`;
			} else {
				errorMessage = `Failed to fetch. This likely means you specified the wrong endpoint in GRID Settings, or your local model provider like Ollama is powered off.`;
			}
		}

		captureLLMEvent(`${loggingName} - Error`, { error: errorMessage });
		onError_({ message: errorMessage, fullError });
	};

	// we should NEVER call onAbort internally, only from the outside
	const onAbort = () => {
		captureLLMEvent(`${loggingName} - Abort`, { messageLengthSoFar: _fullTextSoFar.length });
		try {
			_aborter?.();
		} catch (e) {
			// aborter sometimes automatically throws an error
		}
		_didAbort = true;
	};
	abortRef_.current = onAbort;

	if (messagesType === 'chatMessages') {captureLLMEvent(`${loggingName} - Sending Message`, {});}
	else if (messagesType === 'FIMMessage')
		{captureLLMEvent(`${loggingName} - Sending FIM`, {
			prefixLen: messages_?.prefix?.length,
			suffixLen: messages_?.suffix?.length,
		});}

	try {
		// Skip "auto" - it's not a real provider
		if (providerName === 'auto') {
			onError({ message: `Error: Cannot use "auto" provider - must resolve to a real model first.`, fullError: null });
			return;
		}
		const implementation = sendLLMMessageToProviderImplementation[providerName];
		if (!implementation) {
			onError({ message: `Error: Provider "${providerName}" not recognized.`, fullError: null });
			return;
		}
		const { sendFIM, sendChat } = implementation;
		if (messagesType === 'chatMessages') {
			await sendChat({
				messages: messages_,
				onText,
				onFinalMessage,
				onError,
				settingsOfProvider,
				modelSelectionOptions,
				overridesOfModel,
				modelName,
				_setAborter,
				providerName,
				separateSystemMessage,
				chatMode,
				mcpTools,
			});
			return;
		}
		if (messagesType === 'FIMMessage') {
			if (sendFIM) {
				// Infer featureName from loggingName for max_tokens optimization
				// "Autocomplete" -> 'Autocomplete', others default to undefined (safe default)
				const inferredFeatureName: FeatureName | undefined =
					loggingName === 'Autocomplete' ? 'Autocomplete' : undefined;
				await sendFIM({
					messages: messages_,
					onText,
					onFinalMessage,
					onError,
					settingsOfProvider,
					modelSelectionOptions,
					overridesOfModel,
					modelName,
					_setAborter,
					providerName,
					separateSystemMessage,
					featureName: inferredFeatureName,
				});
				return;
			}
			onError({ message: `Error running Autocomplete with ${providerName} - ${modelName}.`, fullError: null });
			return;
		}
		onError({ message: `Error: Message type "${messagesType}" not recognized.`, fullError: null });
		return;
	} catch (error) {
		if (error instanceof Error) {
			onError({ message: error + '', fullError: error });
		} else {
			onError({ message: `Unexpected Error in sendLLMMessage: ${error}`, fullError: error });
		}
		// ; (_aborter as any)?.()
		// _didAbort = true
	}
};
